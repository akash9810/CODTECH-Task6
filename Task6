z = "New folder\PNEUMONIA_DETECTION-main"

import os, shutil
import random
import numpy as np
import pandas as pd
import cv2
import skimage
import matplotlib.pyplot as plt
import skimage.segmentation
import seaborn as sns
%matplotlib inline
plt.style.use('ggplot')

labels = ['PNEUMONIA','NORMAL']
img_size = 128
def get_data(data_dir):
    data=[]
    for label in labels:
#         train/PNEUMONIA
        path = os.path.join(data_dir, label)
        class_num = labels.index(label)
        for img in os.listdir(path):
            try:
                img_path = os.path.join(path, img)#added by meeeee
                img_arr = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
                if img_arr is None:  # Check if the image is loaded successfully
                    print(f"Failed to load image: {img_path}")
                    continue
                resized_arr = cv2.resize(img_arr, (img_size, img_size))
                data.append([resized_arr, class_num])
            except Exception as e:
                print(f"Error loading image {img_path}: {e}")
    return np.array(data, dtype=object)

def plot_class_distribution(labels):
    sns.countplot(x=labels, palette='viridis')
    plt.title("Class Distribution")
    plt.xlabel("Class")
    plt.ylabel("Count")
    plt.show()

# Assuming you load the data with get_data(), after loading the labels
train_labels = train[:, 1]  # For example, using the train dataset
plot_class_distribution(train_labels)


#new graph



train = get_data("chest_xray/chest_xray/train")
test = get_data("chest_xray/chest_xray/test")
val = get_data("chest_xray/chest_xray/val")


pneumonia = os.listdir("chest_xray/chest_xray/train/PNEUMONIA")
penomina_dir = "chest_xray/chest_xray/train/PNEUMONIA"



plt.figure(figsize=(20,10))

for i in range(9):
    plt.subplot(3,3, i+1)
    img = plt.imread(os.path.join(penomina_dir, pneumonia[i]))
    plt.imshow(img, cmap='gray')
    plt.axis("off")
    plt.title("Pneumonia X-ray")
plt.tight_layout()


normal = os.listdir("chest_xray/chest_xray/train/NORMAL")
normal_dir = "chest_xray/chest_xray/train/NORMAL"


plt.figure(figsize=(20,10))

for i in range(9):
    plt.subplot(3,3, i+1)
    img = plt.imread(os.path.join(normal_dir, normal[i]))
    plt.imshow(img, cmap='gray')
    plt.axis("off")
    plt.title("Normal X-ray")
plt.tight_layout()

listx = []
for i in train:
    if(i[1] == 0):
        listx.append("Pneumonia")
    else:
        listx.append("Normal")
sns.countplot(x=listx)





# Data Augmentation & Resizing

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Model
from tensorflow.keras.models import load_model
from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D,Dropout
from tensorflow.keras.applications.vgg19 import VGG19
from tensorflow.keras.optimizers import SGD, RMSprop, Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau


import os
print(os.getcwd())


train_datagen = ImageDataGenerator(rescale = 1. / 255, 
                  horizontal_flip=0.4,
                  vertical_flip=0.4,
                  rotation_range=40,
                  shear_range=0.2,
                  width_shift_range=0.4,
                  height_shift_range=0.4,
                  fill_mode="nearest")
valid_datagen = ImageDataGenerator(rescale = 1./255)
test_datagen = ImageDataGenerator(rescale = 1./255)



#edited code resuse old 
train_generator = train_datagen.flow_from_directory(
    r"C:\Users\user\weather project\New folder\PNEUMONIA_DETECTION-main\PNEUMONIA_DETECTION-main\chest_xray\chest_xray\train", 
    batch_size=32,
    target_size=(128, 128),  # Resizes the images to 128x128
    class_mode='categorical',  # Since it's a classification problem
    shuffle=True,
    seed=42,
    color_mode='rgb'  # Loading in RGB format
)

valid_generator = valid_datagen.flow_from_directory(
    r"C:\Users\user\weather project\New folder\PNEUMONIA_DETECTION-main\PNEUMONIA_DETECTION-main\chest_xray\chest_xray\val", 
    batch_size=32,
    target_size=(128, 128),
    class_mode='categorical',
    shuffle=True,
    seed=42,
    color_mode='rgb'
)

test_generator = test_datagen.flow_from_directory(
    r"C:\Users\user\weather project\New folder\PNEUMONIA_DETECTION-main\PNEUMONIA_DETECTION-main\chest_xray\chest_xray\test", 
    batch_size=32,
    target_size=(128, 128),
    class_mode='categorical',
    shuffle=False,  # For testing, we usually don't shuffle
    seed=42,
    color_mode='rgb'
)


class_labels = train_generator.class_indices
class_labels

class_name = {value:key for (key, value) in class_labels.items()}

class_name


# VGG19 CNN Architecture



base_model = VGG19(input_shape = (128,128,3),
                     include_top = False,
                     weights = 'imagenet')
for layer in base_model.layers:
    layer.trainable = False

x = base_model.output
flat = Flatten()(x)


class_1 = Dense(4608, activation = 'relu')(flat)
dropout = Dropout(0.2)(class_1)
class_2 = Dense(1152, activation = 'relu')(dropout)
output = Dense(2, activation = 'softmax')(class_2)

model_01 = Model(base_model.inputs, output)
model_01.summary()


filepath = "model.keras"
es = EarlyStopping(monitor="val_loss", verbose=1, mode="min", patience=4)
cp=ModelCheckpoint(filepath, monitor="val_loss", save_best_only=True, save_weights_only=False,mode="auto", save_freq="epoch")
lrr = ReduceLROnPlateau(monitor="val_accuracy", patience=3, verbose=1, factor=0.5, min_lr=0.0001)

sgd = SGD(learning_rate=0.0001, decay = 1e-6, momentum=0.9, nesterov = True)

model_01.compile(loss="categorical_crossentropy", optimizer=sgd, metrics=['accuracy'])


# history_01 = model_01.fit(train_generator, 
#             steps_per_epoch=50,
#             epochs=20, 
#             callbacks=[es, cp, lrr],
#             validation_data=valid_generator)
history_01 = model_01.fit(
    train_generator, 
    steps_per_epoch=100,  # Use full training data
    epochs=50,  # Start with a large number; early stopping will control actual training
    callbacks=[es, cp, lrr],
    validation_data=valid_generator,
    
)


if not os.path.isdir('model_weights/'):
    os.mkdir("model_weights/")
model_01.save(filepath = "model_weights/vgg19_model_01.h5", overwrite=True)



test_generator = test_datagen.flow_from_directory("chest_xray/chest_xray/test",
                                 batch_size = 32,
                                 target_size=(128,128),
                                 class_mode = 'categorical',
                                 shuffle=True,
                                 seed = 42,
                                 color_mode = 'rgb')



model_01.load_weights("model_weights/vgg19_model_01.h5")

vgg_val_eval_01 = model_01.evaluate(valid_generator)
vgg_test_eval_01 = model_01.evaluate(test_generator)




print(f"Validation Loss: {vgg_val_eval_01[0]}")
print(f"Validation Accuarcy: {vgg_val_eval_01[1]}")
print(f"Test Loss: {vgg_test_eval_01[0]}")
print(f"Test Accuarcy: {vgg_test_eval_01[1]}")



base_model = VGG19(include_top=False, input_shape=(128,128,3))
base_model_layer_names = [layer.name for layer in base_model.layers]

x = base_model.output
flat = Flatten()(x)


class_1 = Dense(4608, activation = 'relu')(flat)
dropout = Dropout(0.2)(class_1)
class_2 = Dense(1152, activation = 'relu')(dropout)
output = Dense(2, activation = 'softmax')(class_2)

model_02 = Model(base_model.inputs, output)
model_02.load_weights("model_weights/vgg19_model_01.h5")

set_trainable = False
for layer in base_model.layers:
    if layer.name in [ 'block5_conv3','block5_conv4']:
        set_trainable=True
    if set_trainable:
        set_trainable=True
    else:
        set_trainable=False
print(model_02.summary())

base_model_layer_names


sgd = SGD(learning_rate=0.0001, decay = 1e-6, momentum=0.9, nesterov = True)

model_02.compile(loss="categorical_crossentropy", optimizer=sgd, metrics=['accuracy'])



history_02 = model_02.fit(train_generator, 
            steps_per_epoch=32,
            epochs=20, 
            callbacks=[es, cp, lrr],
            validation_data=valid_generator)



if not os.path.isdir('model_weights/'):
    os.mkdir("model_weights/")
model_02.save(filepath = "model_weights/vgg19_model_02.keras", overwrite=True)





model_02.load_weights("model_weights/vgg19_model_02.keras")

vgg_val_eval_02 = model_02.evaluate(valid_generator)
vgg_test_eval_02 = model_02.evaluate(test_generator)

print(f"Validation Loss: {vgg_val_eval_02[0]}")
print(f"Validation Accuarcy: {vgg_val_eval_02[1]}")
print(f"Test Loss: {vgg_test_eval_02[0]}")
print(f"Test Accuarcy: {vgg_test_eval_02[1]}")


# Unfreezing and fine tuning the entire network


base_model = VGG19(include_top=False, input_shape=(128,128,3))

x = base_model.output
flat = Flatten()(x)

class_1 = Dense(4608, activation = 'relu')(flat)
dropout = Dropout(0.2)(class_1)
class_2 = Dense(1152, activation = 'relu')(dropout)
output = Dense(2, activation = 'softmax')(class_2)

model_03 = Model(base_model.inputs, output)
model_03.load_weights("model_weights/vgg19_model_01.h5")

#meaddad

#vgg_val_eval_03 = model_03.evaluate(valid_generator)
#vgg_test_eval_03 = model_03.evaluate(test_generator)

#print(f"Validation Loss: {vgg_val_eval_03[0]}")
#print(f"Validation Accuarcy: {vgg_val_eval_03[1]}")
#print(f"Test Loss: {vgg_test_eval_03[0]}")
#print(f"Test Accuarcy: {vgg_test_eval_03[1]}")



#////////////////////////

print(model_03.summary())


sgd = SGD(learning_rate=0.0001, decay = 1e-6, momentum=0.9, nesterov = True)

model_03.compile(loss="categorical_crossentropy", optimizer=sgd, metrics=['accuracy'])



history_03 = model_02.fit(train_generator, 
            steps_per_epoch=100,
            epochs=20, 
            callbacks=[es, cp, lrr],
            validation_data=valid_generator)


# if not os.path.isdir('model_weights/'):
#     os.mkdir("model_weights/")
# model_03.save(filepath = "model_weights/vgg19_model_01.keras", overwrite=True)
import os
if not os.path.isdir('model_weights/'):
    os.mkdir("model_weights/")

# Save the model
model_03.save(filepath="model_weights/vgg19_model_01.keras", overwrite=True)

print("Model saved successfully!")

from tensorflow.keras.preprocessing.image import load_img, img_to_array
import numpy as np

# Define class labels
class_labels = ["Normal", "Pneumonia"]



# Load and preprocess the test image


#test_image_path = 'C://Users/user/weather project/New folder/test/NORMAL/IM-0009-0001.jpeg'  # Replace with the path to your test image
#test_image_path = 'C://Users/user/weather project/New folder/test/PNEUMONIA/person31_virus_70.jpeg'  # Replace with the path to your test image


#test_image_path = 'C://Users/user/weather project/New folder/test/NORMAL/NORMAL2-IM-0366-0001.jpeg'  # Replace with the path to your test image
#test_image_path = 'C://Users/user/weather project/New folder/test/PNEUMONIA/person136_bacteria_650.jpeg'  # Replace with the path to your test image

test_image_path = 'C://Users/user/weather project/New folder/test/PNEUMONIA/person1_virus_13.jpeg'




image = load_img(test_image_path, target_size=(128, 128))  # Resize to match input shape
image_array = img_to_array(image)  # Convert to NumPy array
image_array = np.expand_dims(image_array, axis=0)  # Add batch dimension
image_array = image_array / 255.0  # Normalize pixel values to [0, 1]

# Predict using the model
prediction = model_01.predict(image_array)
predicted_class = np.argmax(prediction, axis=1)[0]  # Get the index of the predicted class
predicted_label = class_labels[predicted_class]  # Map the index to the corresponding label

# Output the results
print("Predicted Probabilities:", prediction)
print("Predicted Class Label:", predicted_label)
